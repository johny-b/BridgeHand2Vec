{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPt9IWYT8BIQ"
   },
   "source": [
    "# Loading and preprocessing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s6zfQa6EUqzG",
    "outputId": "d1231095-e5bf-40aa-f530-d5de7026ded1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 10:31:32.031207: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-25 10:31:32.632795: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-25 10:31:32.635198: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-25 10:31:34.584545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 24\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "def preprocess_file(f_name):\n",
    "  df = pd.read_csv(f_name, sep=';', index_col=0).reset_index(drop=True)\n",
    "  df[['S', 'H', 'D', 'C']] = df.PBN.str.split('.', expand=True)\n",
    "  colors = ['S', 'H', 'D', 'C']\n",
    "  values = ['A', 'K', 'Q', 'J', 'T', '9', '8', '7', '6', '5', '4', '3', '2']\n",
    "  for color in colors:\n",
    "    for val in values:\n",
    "      df.loc[:, val+color] = 0.\n",
    "      df.loc[df[color].str.find(val)!=-1, val+color] = 1.\n",
    "  df.loc[:, 'Pts'] = (df['AS']+df['AH']+df['AD']+df['AC'])*4+(df['KS']+df['KH']+df['KD']+df['KC'])*3+(df['QS']+df['QH']+df['QD']+df['QC'])*2+(df['JS']+df['JH']+df['JD']+df['JC'])\n",
    "  df['#S'] = df.loc[:, 'AS':'2S'].sum(axis=1)\n",
    "  df['#H'] = df.loc[:, 'AH':'2H'].sum(axis=1)\n",
    "  df['#D'] = df.loc[:, 'AD':'2D'].sum(axis=1)\n",
    "  df['#C'] = df.loc[:, 'AC':'2C'].sum(axis=1)\n",
    "  df['#A'] = df['AS']+df['AH']+df['AD']+df['AC']\n",
    "  df['#K'] = df['KS']+df['KH']+df['KD']+df['KC']\n",
    "  df['#Q'] = df['QS']+df['QH']+df['QD']+df['QC']\n",
    "  df['#J'] = df['JS']+df['JH']+df['JD']+df['JC']\n",
    "\n",
    "  df.loc[:, ['l0', 'l1', 'l2', 'l3', 'l4', 'cp', 'cc', 'cd', 'ch', 'cs', 'cn']] = 0.\n",
    "  df.loc[df['OPENING']=='PASS', 'OPENING'] = '0P'\n",
    "  df.loc[df['OPENING'].str[0]=='0', 'l0'] = 1.\n",
    "  df.loc[df['OPENING'].str[0]=='1', 'l1'] = 1.\n",
    "  df.loc[df['OPENING'].str[0]=='2', 'l2'] = 1.\n",
    "  df.loc[df['OPENING'].str[0]=='3', 'l3'] = 1.\n",
    "  df.loc[df['OPENING'].str[0]=='4', 'l4'] = 1.\n",
    "  df.loc[df['OPENING'].str[1]=='P', 'cp'] = 1.\n",
    "  df.loc[df['OPENING'].str[1]=='C', 'cc'] = 1.\n",
    "  df.loc[df['OPENING'].str[1]=='D', 'cd'] = 1.\n",
    "  df.loc[df['OPENING'].str[1]=='H', 'ch'] = 1.\n",
    "  df.loc[df['OPENING'].str[1]=='S', 'cs'] = 1.\n",
    "  df.loc[df['OPENING'].str[1]=='N', 'cn'] = 1.\n",
    "  df.drop(['PBN', 'OPENING', 'S', 'H', 'D', 'C'], axis=1, inplace=True)\n",
    "  return df\n",
    "\n",
    "\n",
    "df_train = preprocess_file(\"../data/openings/train.csv\")\n",
    "train_x, val_x = df_train.loc[:699, 'AS':'#J'], df_train.loc[700:, 'AS':'#J']\n",
    "train_y, val_y = df_train.loc[:699, 'l0':'cn'], df_train.loc[700:, 'l0':'cn']\n",
    "\n",
    "df_test = preprocess_file(\"../data/openings/test.csv\")\n",
    "test_x, test_y = df_test.loc[:, 'AS':'#J'], df_test.loc[:, 'l0':'cn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XRigJYo8Hi4"
   },
   "source": [
    "# Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-V5WurmMyr-k"
   },
   "outputs": [],
   "source": [
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "  def __init__(self, save_best_metric='val_loss', this_max=False):\n",
    "    self.save_best_metric = save_best_metric\n",
    "    self.max = this_max\n",
    "    if this_max:\n",
    "      self.best = float('-inf')\n",
    "    else:\n",
    "      self.best = float('inf')\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    metric_value = logs[self.save_best_metric]\n",
    "    if self.max:\n",
    "      if metric_value > self.best:\n",
    "        self.best = metric_value\n",
    "        self.best_weights = self.model.get_weights()\n",
    "    else:\n",
    "      if metric_value < self.best:\n",
    "        self.best = metric_value\n",
    "        self.best_weights= self.model.get_weights()\n",
    "\n",
    "\n",
    "class BridgeModel():\n",
    "  def __init__(self):\n",
    "    self.model_level = None\n",
    "    self.model_color = None\n",
    "\n",
    "  def preprocess_input(self, x):\n",
    "    pass\n",
    "\n",
    "  def preprocess_output(self, y):\n",
    "    return y.loc[:, 'l0':'l4'], y.loc[:, 'cp':'cn']\n",
    "\n",
    "  def train(self, x, y, val_x, val_y, epochs=50, batch_size=10, verbose=False):\n",
    "    x = self.preprocess_input(x)\n",
    "    y_l, y_c = self.preprocess_output(y)\n",
    "    val_x = self.preprocess_input(val_x)\n",
    "    val_y_l, val_y_c = self.preprocess_output(val_y)\n",
    "    save_best_model = SaveBestModel(save_best_metric=\"val_accuracy\", this_max=True)\n",
    "    hist_l = self.model_level.fit(x, y_l, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y_l), verbose=verbose, callbacks=[save_best_model])\n",
    "    self.model_level.set_weights(save_best_model.best_weights)\n",
    "    save_best_model = SaveBestModel(save_best_metric=\"val_accuracy\", this_max=True)\n",
    "    hist_c = self.model_color.fit(x, y_c, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y_c), verbose=verbose, callbacks=[save_best_model])\n",
    "    self.model_color.set_weights(save_best_model.best_weights)\n",
    "    return hist_l, hist_c\n",
    "\n",
    "  def predict(self, data):\n",
    "    levels = self.model_level.predict(self.preprocess_input(data))\n",
    "    colors = self.model_color.predict(self.preprocess_input(data))\n",
    "    out_df = pd.DataFrame(np.concatenate([levels, colors], axis=1), columns=['l0', 'l1', 'l2', 'l3', 'l4', 'cp', 'cc', 'cd', 'ch', 'cs', 'cn'], index=data.index)\n",
    "    out_df.loc[out_df.loc[:, 'l0':'l4'].idxmax(axis=1)=='l0', 'cp'] = 1\n",
    "    out_df.loc[out_df.loc[:, 'l0':'l4'].idxmax(axis=1)=='l0', 'cc':'cn'] = 0\n",
    "    out_df.loc[out_df.loc[:, 'cp':'cn'].idxmax(axis=1)=='cp', 'l0'] = 1\n",
    "    out_df.loc[out_df.loc[:, 'cp':'cn'].idxmax(axis=1)=='cp', 'l1':'l4'] = 0\n",
    "    return out_df\n",
    "\n",
    "  def evaluate(self, x, y):\n",
    "    preds = self.predict(x)\n",
    "    good_levels = preds.loc[:, 'l0':'l4'].idxmax(axis=1)==y.loc[:, 'l0':'l4'].idxmax(axis=1)\n",
    "    good_colors = preds.loc[:, 'cp':'cn'].idxmax(axis=1)==y.loc[:, 'cp':'cn'].idxmax(axis=1)\n",
    "    return (good_levels & good_colors).sum()/len(x)\n",
    "      \n",
    "  def load_weights(self, level_fname, color_fname):\n",
    "    self.model_level.load_weights(level_fname)\n",
    "    self.model_color.load_weights(color_fname)\n",
    "\n",
    "  def save_weights(self, level_fname, color_fname):\n",
    "    self.model_level.save_weights(level_fname)\n",
    "    self.model_color.save_weights(color_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yf-s1fqTZeiM"
   },
   "source": [
    "# Raw model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GKmOhdb8sYpA"
   },
   "outputs": [],
   "source": [
    "class ModelRaw(BridgeModel):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.model_level = tf.keras.models.Sequential([\n",
    "        layers.Input(shape=(52)),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    self.model_color = tf.keras.models.Sequential([\n",
    "        layers.Input(shape=(52)),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(6, activation='softmax')\n",
    "    ])\n",
    "    self.model_level.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics = [\"accuracy\"])\n",
    "    self.model_color.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics = [\"accuracy\"])\n",
    "\n",
    "  def preprocess_input(self, x):\n",
    "    return x.loc[:, 'AS':'2C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "puuvqIz8K0_a",
    "outputId": "68267bdb-b187-4b12-dbfc-a652555e6c36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "0.82\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "0.6566666666666666\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "0.6948356807511737\n"
     ]
    }
   ],
   "source": [
    "model_raw = ModelRaw()\n",
    "model_raw.train(train_x, train_y, val_x, val_y)\n",
    "model_raw.train(train_x, train_y, val_x, val_y)\n",
    "print(model_raw.evaluate(train_x, train_y))\n",
    "print(model_raw.evaluate(val_x, val_y))\n",
    "print(model_raw.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CO1Bxzg5Zk_V"
   },
   "source": [
    "# Heuristic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "C4KDq10HZbjj"
   },
   "outputs": [],
   "source": [
    "class ModelHeuristic(BridgeModel):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.model_level = tf.keras.models.Sequential([\n",
    "        layers.Input(shape=9),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    self.model_color = tf.keras.models.Sequential([\n",
    "        layers.Input(shape=(9)),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(6, activation='softmax')\n",
    "    ])\n",
    "    self.model_level.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics = [\"accuracy\"])\n",
    "    self.model_color.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics = [\"accuracy\"])\n",
    "\n",
    "  def preprocess_input(self, x):\n",
    "    return x.loc[:, 'Pts':'#J']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AqrCuuqQG3B",
    "outputId": "0eceeea7-1eb6-49a5-838d-7e6748d50e56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "0.8342857142857143\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "0.8066666666666666\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "0.7887323943661971\n"
     ]
    }
   ],
   "source": [
    "model_heuristic = ModelHeuristic()\n",
    "model_heuristic.train(train_x, train_y, val_x, val_y)\n",
    "model_heuristic.train(train_x, train_y, val_x, val_y)\n",
    "print(model_heuristic.evaluate(train_x, train_y))\n",
    "print(model_heuristic.evaluate(val_x, val_y))\n",
    "print(model_heuristic.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcYk8yBpZutD"
   },
   "source": [
    "# Combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DgcaASfwZtLM"
   },
   "outputs": [],
   "source": [
    "class ModelCombined(BridgeModel):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.model_level = tf.keras.models.Sequential([\n",
    "        layers.Input(shape=61),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    self.model_color = tf.keras.models.Sequential([\n",
    "        layers.Input(shape=(61)),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(6, activation='softmax')\n",
    "    ])\n",
    "    self.model_level.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics = [\"accuracy\"])\n",
    "    self.model_color.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics = [\"accuracy\"])\n",
    "\n",
    "  def preprocess_input(self, x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFYKZ_46VOyX",
    "outputId": "38d05721-1095-4ef8-fe6d-3aac0f045b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "0.7914285714285715\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "0.7033333333333334\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "0.7183098591549296\n"
     ]
    }
   ],
   "source": [
    "model_combined = ModelCombined()\n",
    "model_combined.train(train_x, train_y, val_x, val_y)\n",
    "model_combined.train(train_x, train_y, val_x, val_y)\n",
    "print(model_combined.evaluate(train_x, train_y))\n",
    "print(model_combined.evaluate(val_x, val_y))\n",
    "print(model_combined.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPaV_84sZx6M"
   },
   "source": [
    "# Expert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zVd7XGxeZl9d"
   },
   "outputs": [],
   "source": [
    "class ModelExpert(BridgeModel):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def preprocess_input(self, x):\n",
    "    return x\n",
    "\n",
    "  def predict_one(self, row):\n",
    "    out = pd.Series(index=['l0', 'l1', 'l2', 'l3', 'l4', 'cp', 'cc', 'cd', 'ch', 'cs', 'cn'], dtype=float)\n",
    "    out[:] = 0\n",
    "    if row['Pts'] >= 18:\n",
    "      out['l1'] = 1\n",
    "      out['cc'] = 1\n",
    "    elif row['Pts'] >= 12:\n",
    "      if row['#S'] >= 5:\n",
    "        out['l1'] = 1\n",
    "        out['cs'] = 1\n",
    "      elif row['#H'] >= 5:\n",
    "        out['l1'] = 1\n",
    "        out['ch'] = 1\n",
    "      elif row['Pts'] >= 15:\n",
    "        if ((row['#S':'#C'].min()==2 and row['#S':'#C'].max()==4) or \n",
    "            (row['#C']==5 and row['#S':'#D'].min()==2 and row['#S':'#D'].max()==3) or\n",
    "            (row['#D']==5 and row[['#S', '#H', '#C']].min()==2 and row[['#S', '#H', '#C']].max()==3)):\n",
    "          out['l1'] = 1\n",
    "          out['cn'] = 1\n",
    "        elif row['#D']>=row['#C']:\n",
    "          out['l1'] = 1\n",
    "          out['cd'] = 1\n",
    "        else:\n",
    "          out['l1'] = 1\n",
    "          out['cc'] = 1\n",
    "      elif (row['#D']>=5 or\n",
    "            (row['#D']==4 and row['#C']==5) or\n",
    "            (row['#D']==4 and row[['#S', '#H', '#C']].min()==1)):\n",
    "        out['l1'] = 1\n",
    "        out['cd'] = 1\n",
    "      elif (row['#C']>=6 or\n",
    "            ((row['#H']==4 or row['#S']==4) and row['#C']==5)):\n",
    "            out['l2'] = 1\n",
    "            out['cc'] = 1\n",
    "      else:\n",
    "        out['l1'] = 1\n",
    "        out['cc'] = 1\n",
    "    elif row['Pts'] >= 7:\n",
    "      if row['#S']==6 or row['#H']==6:\n",
    "        out['l2'] = 1\n",
    "        out['cd'] = 1\n",
    "      elif row['#H']==5 and row[['#S', '#D', '#C']].max()>=5:\n",
    "        out['l2'] = 1\n",
    "        out['ch'] = 1\n",
    "      elif row['#S']==5 and row['#D':'#C'].max()>=5:\n",
    "        out['l2'] = 1\n",
    "        out['cs'] = 1\n",
    "      elif row['#D']>=5 and row['#C']>=5:\n",
    "        out['l2'] = 1\n",
    "        out['cn'] = 1\n",
    "      elif row['#C']==7:\n",
    "        out['l3'] = 1\n",
    "        out['cc'] = 1\n",
    "      elif row['#D']==7:\n",
    "        out['l3'] = 1\n",
    "        out['cd'] = 1\n",
    "      elif row['#H']==7:\n",
    "        out['l3'] = 1\n",
    "        out['ch'] = 1\n",
    "      elif row['#S']==7:\n",
    "        out['l3'] = 1\n",
    "        out['cs'] = 1\n",
    "      elif row['#C']==8:\n",
    "        out['l4'] = 1\n",
    "        out['cc'] = 1\n",
    "      elif row['#D']==8:\n",
    "        out['l4'] = 1\n",
    "        out['cd'] = 1\n",
    "      elif row['#H']==8:\n",
    "        out['l4'] = 1\n",
    "        out['ch'] = 1\n",
    "      elif row['#S']==8:\n",
    "        out['l4'] = 1\n",
    "        out['cs'] = 1\n",
    "      else:\n",
    "        out['l0'] = 1\n",
    "        out['cp'] = 1\n",
    "    else:\n",
    "      out['l0'] = 1\n",
    "      out['cp'] = 1\n",
    "    return out\n",
    "\n",
    "  def predict(self, data):\n",
    "    return data.apply(self.predict_one, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eahPpMn3cr2J",
    "outputId": "e8329a7f-d9d5-486d-cd2a-fbed268f337b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8471428571428572\n",
      "0.87\n",
      "0.812206572769953\n"
     ]
    }
   ],
   "source": [
    "model_expert = ModelExpert()\n",
    "print(model_expert.evaluate(train_x, train_y))\n",
    "print(model_expert.evaluate(val_x, val_y))\n",
    "print(model_expert.evaluate(test_x, test_y))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
